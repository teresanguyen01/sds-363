---
title: "S&DS_Pset1-1"
output: html_document
date: "2025-01-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
#This chunk defines several helpful functions

#n is the number of observations in the dataset
#p is the number of variables in the dataset

parallel<-function(n,p){
  
  if (n > 1000 || p > 100) {
    print ("Sorry, this only works for n<1000 and p<100")
    stop()
  }
  
  coefs <- matrix(
    c(0.0316, 0.7611, -0.0979, -0.3138, 0.9794, -.2059, .1226, 0, 0.1162, 
      0.8613, -0.1122, -0.9281, -0.3781, 0.0461, 0.0040, 1.0578, 0.1835, 
      0.9436, -0.1237, -1.4173, -0.3306, 0.0424, .0003, 1.0805 , 0.2578, 
      1.0636, -0.1388, -1.9976, -0.2795, 0.0364, -.0003, 1.0714, 0.3171, 
      1.1370, -0.1494, -2.4200, -0.2670, 0.0360, -.0024, 1.08994, 0.3809, 
      1.2213, -0.1619, -2.8644, -0.2632, 0.0368, -.0040, 1.1039, 0.4492, 
      1.3111, -0.1751, -3.3392, -0.2580, 0.0360, -.0039, 1.1173, 0.5309, 
      1.4265, -0.1925, -3.8950, -0.2544, 0.0373, -.0064, 1.1421, 0.5734, 
      1.4818, -0.1986, -4.2420, -0.2111, 0.0329, -.0079, 1.1229, 0.6460, 
      1.5802, -0.2134, -4.7384, -0.1964, 0.0310, -.0083, 1.1320),ncol=8, byrow=TRUE)
  
  calclim <- p
  if (p > 10) calclim <- 10
  coefsred <- coefs[1:calclim, ]
  temp <- c(p:1)
  #stick <- sort(cumsum(1/temp), decreasing=TRUE)[1:calclim]
  multipliers <- matrix(c(log(n),log(p),log(n)*log(p),1), nrow=1)
  longman <- exp(multipliers%*%t(coefs[,1:4]))[1:calclim]
  allen <- rep(NA, calclim)
  leig0 <- 0
  newlim <- calclim
  if (calclim+2 < p) newlim <-newlim+2
  for (i in 1:(newlim-2)){
    leig1 <- coefsred[i,5:8]%*%matrix(c(1,log(n-1),log((p-i-1)*(p-i+2)/2), leig0))
    leig0 <- leig1
    allen[i] <- exp(leig1)
  }
  pcompnum <- c(1:calclim)
  #data.frame(cbind(pcompnum,stick,longman,allen))
  data.frame(cbind(pcompnum,longman,allen))  
}

#########
#this function makes a nice plot if given the input from a PCA analysis
#created by prcomp()
##
#arguments are
#    n=number of observations

parallelplot <- function(comp){
  if (dim(comp$x)[1] > 1000 || length(comp$sdev) > 100) {
    print ("Sorry, this only works for n < 1000 and p < 100")
    stop()
  }
  #if (round(length(comp$sdev)) < round(sum(comp$sdev^2))) {
  #    print ("Sorry, this only works for analyses using the correlation matrix")
  #    stop()
  # }
  
  parallelanal <- parallel(dim(comp$x)[1], length(comp$sdev))
  print(parallelanal)
  calclim <- min(10, length(comp$sdev))
  eigenvalues <- (comp$sdev^2)[1:calclim]
  limits <- as.matrix(parallelanal[,2:3])
  limits <- limits[complete.cases(limits)]
  ymax <- range(c(eigenvalues),limits)
  plot(parallelanal$pcompnum, eigenvalues, xlab="Principal Component Number",
       ylim=c(ymax), ylab="Eigenvalues and Thresholds",
       main="Scree Plot with Parallel Analysis Limits",type="b",pch=15,lwd=2, col="red")
  #lines(parallelanal$pcompnum,parallelanal[,2], type="b",col="red",pch=16,lwd=2)
  lines(parallelanal$pcompnum,parallelanal[,2], type="b",col="green",pch=17,lwd=2)
  lines(parallelanal$pcompnum,parallelanal[,3], type="b",col="blue",pch=18,lwd=2)
  #legend((calclim/2),ymax[2],legend=c("Eigenvalues","Stick Method","Longman Method","Allen Method"),  pch=c(15:18), col=c("black","red","green","blue"),lwd=2)
  legend((calclim/2), ymax[2], legend=c("Eigenvalues","Longman Method","Allen Method"),  pch = c(16:18), col= c("red","green","blue"), lwd=2)
}


#make score plot with confidence ellipse.
#arguments are output from prcomp, vector with components for plotting (usually c(1,2) or c(1,3)
#and a vector of names for the points

ciscoreplot<-function(x, comps, namevec){
  y1<-sqrt(5.99*(x$sdev[comps[1]]^2))
  ymod<-y1-y1%%.05
  y1vec<-c(-y1,seq(-ymod,ymod,by=0.05),y1)
  y2vecpos<-sqrt((5.99-(y1vec^2)/x$sdev[comps[1]]^2)*x$sdev[comps[2]]^2)
  y2vecneg<--sqrt((5.99-(y1vec^2)/x$sdev[comps[1]]^2)*x$sdev[comps[2]]^2)
  y2vecpos[1]<-0
  y2vecneg[1]<-0
  y2vecpos[length(y2vecpos)]<-0
  y2vecneg[length(y2vecneg)]<-0
  
  plot(x$x[,comps[1]],x$x[,comps[2]], 
       pch = 19, 
       cex = 1.2,
       xlim = c(min(y1vec, x$x[, comps[1]]), max(y1vec, x$x[, comps[1]])),
       ylim = c(min(y2vecneg, x$x[, comps[2]]), max(y2vecpos, x$x[, comps[2]])),
       main = "PC Score Plot with 95% CI Ellipse", 
       xlab = paste("Scores for PC", comps[1], sep = " "), 
       ylab = paste("Scores for PC", comps[2], sep = " "))
  
  lines(y1vec,y2vecpos,col="Red",lwd=2)
  lines(y1vec,y2vecneg,col="Red",lwd=2)
  outliers<-((x$x[,comps[1]]^2)/(x$sdev[comps[1]]^2)+(x$x[,comps[2]]^2)/(x$sdev[comps[2]]^2))>5.99
  
  points(x$x[outliers, comps[1]], x$x[outliers, comps[2]], pch = 19, cex = 1.2, col = "Blue")
  
  text(x$x[outliers, comps[1]],x$x[outliers, comps[2]], col = "Blue", lab = namevec[outliers])
}

```


```{r}
data <- read.csv("../../Documents/sds-363/Human Development Index - Full.csv")

data <- data[, c(
  "Country",
  "UNDP.Developing.Regions",
  "HDI.Rank..2021.",
  "Human.Development.Index..2021.",
  "Life.Expectancy.at.Birth..2021.",
  "Mean.Years.of.Schooling..2021.",
  "Gross.National.Income.Per.Capita..2021.",
  "Gender.Development.Index..2021.",
  "Coefficient.of.human.inequality..2021.",
  "Overall.loss......2021.",
  "Gender.Inequality.Index..2021.",
  "Maternal.Mortality.Ratio..deaths.per.100.000.live.births...2021.",
  "Adolescent.Birth.Rate..births.per.1.000.women.ages.15.19...2021.",
  "Labour.force.participation.rate..female....ages.15.and.older...2021.",
  "Labour.force.participation.rate..male....ages.15.and.older...2021.",
  "Carbon.dioxide.emissions.per.capita..production...tonnes...2021."
)]

colnames(data) <- c(
  "Country",
  "Region",
  "HDI_Rank_2021",
  "HDI_2021",
  "Life_Expectancy_2021",
  "Mean_Years_Schooling_2021",
  "GNI_Per_Capita_2021",
  "Gender_Dev_Index_2021",
  "Human_Inequality_Coeff_2021",
  "Overall_Loss_2021",
  "Gender_Inequality_Index_2021",
  "Maternal_Mortality_Rate_2021",
  "Adolescent_Birth_Rate_2021",
  "Female_Labour_Force_2021",
  "Male_Labour_Force_2021",
  "CO2_Emissions_percapita_2021"
)

data <- data[complete.cases(data), ]
```

```{r, warning=FALSE}
library(corrplot)
#Figure out library for chart.Correlation
corrplot.mixed(cor(data[ ,-c(1:3)]), lower.col = "black", upper = "ellipse", tl.col = "black", number.cex = .3, order = "hclust", tl.pos = "lt", tl.cex = .5)

chart.Correlation(data[, -c(1:3)])
```
*Based on our plots showing the correlation between our variables, there appears to be decently strong positive and negative correlations between our variables, suggesting that PCA may be an effective strategy to utilize since we can reduce dimensionality without losing too much information. Moreover, the relationships exhibited between variables, for the most part, appear to be linear. Looking at the scatter plots between our variables does show some non-linearity (for instance, the relationship between GNI pc and mortality rate), which may suggest the use of transformations.*

```{r}
# MAKE chi-square quantile plot
library(heplots)
cqplot(data[, -c(1:3)], main = "World Bank Data")
```


```{r}
# Apply log transformation to specific columns 
data[c("GNI_Per_Capita_2021", "Gender_Dev_Index_2021", "Maternal_Mortality_Rate_2021", "Adolescent_Birth_Rate_2021", "CO2_Emissions_percapita_2021")] <- lapply(data[c("GNI_Per_Capita_2021", "Gender_Dev_Index_2021", "Maternal_Mortality_Rate_2021", "Adolescent_Birth_Rate_2021", "CO2_Emissions_percapita_2021")], log)

chart.Correlation(data[, -c(1:3)])
```
*We used log transformations of the following variables: GNI PerCapita, Gender Dev Index, Maternal Mortality Rate, Adolescent Birth Rate, and CO2 Emissions percapita. These variables were not distributed normally and thus has non-linear relationships with our other variables, potentially impacting the effectiveness of PCA. Following the transformations of these variables, the distribution (using a histogram) appear to be normal and all of our relationships between the variables are mostly linear.*

```{r}
# MAKE another chi-square quantile plot
library(heplots)
cqplot(data[, -c(1:3)], main = "World Bank Data")
```

```{r}
corrplot(cor(data[ ,-c(1:3)]), method="number", order="FPC", tl.cex = .5, number.cex = .3)
corrplot(cor(data[ ,-c(1:3)]),method = "ellipse", order="FPC", tl.cex = .5)

dim(data)
```
*As mentioned in question 1, there appears to be fairly strong correlations (both positive and negative) between our variables. Based on the corrplot, some variables with very strong positive correlations include overall loss and gender inequality (r = 0.88), birth rate and human inequality coefficient (r = 0.88), and gender inequality and birth rate (r = 0.81). Likewise, there are some decently strong negative correlation between our variables such as mean years of education and human inequality (r = -0.89), gender inequality and life expectancy (r = -0.85) and human inequality and life expectancy (-0.85). This suggests that PCA should work relatively well on our given data since strong correlations implies that a lot of the variance is being described by multiple variables and as such, we can capture a lot of the variability by using a set of principle components (thus reducing our dimensions overall). Our dataset is composed of 150 complete observations and 13 variables (there are 16 total variables but we excluded 3 of them from our analysis since they are categorical). Relative to the number of variables our sample size is sufficiently large enough (there are over 10 times the amount of complete oberservations as variables) and we can use a rule of them to ensure that our data set is large enough for PCA.*

```{r}

summary.PCA.JDRS <- function(x){
  sum_JDRS <- summary(x)$importance
  sum_JDRS[1, ] <- sum_JDRS[1, ]^2
  attr(sum_JDRS, "dimnames")[[1]][1] <- "Eigenvals (Variance)"
  sum_JDRS
}

pc1 <- prcomp(data[, -c(1:3)], scale. = TRUE)

round(summary.PCA.JDRS(pc1),2)

```
*Using the total variance explained by a given number of principle components, we can use a total explained cutoff of 80%. Under this threshold, we would need three principle components to capture at least 80% of the total variance. In this case, the first principal component explains 65% of the total variance, 12% for the second principle component and 6% for the third for a total of 83%. Using the eigenvalues >1 rule, we would only retain the first two principle components with eigenvalues of 8.47 and 1.62 respectively.*

```{r}
screeplot(pc1, type = "lines", col = "red", lwd = 2, pch = 19, cex = 1.2, 
          main = "Scree Plot of Raw WB Data")
```
*Using the scree plot elbow method, there is an apparent elbow at the second principle component (there also looks to be one at the third but this is less clear). Using the second principle component as the cutoff, we would only retain one principle component according to the scree plot.*

```{r}
source("http://reuningscherer.net/multivariate/r/parallel.R.txt")
parallelplot(pc1)
```
*Since parallel analysis assumes that the data is suitable for PCA, we can use it as a valid method to determine the number of principle components to keep - after transforming the data, we have linear relationships between all of our variables and also normality (although this isn't a necessary condition for PCA). Based on parallel analysis, we should retain 2 principle components, since the cutoff is right below the second component.*

```{r}
round(pc1$rotation,2)
```
*Based on our analysis, we decided to retain only the first 2 principle components. The first component appears to be a general measure of overall well being and development: the positive loadings for the first component that are significant include variables such as HDI, life expectancy and mean years of schooling, which are all important benchmarks when judging the development of a country. On the other hand, the loadings that are equally large in magnitude but negative include the inequality level, overall loss, gender inequality and the mortality rate. These loadings are indicative of lesser developed countries which is why they are opposite in sign to the positive loadings, which are the signs of development. Our second principle component describes gender equality. There are three variables with large loadings in magnitude: the gender development index, participation in the female labor force and participation in the male labor force. These variables all share relationships with gender and measure the overall gender equality of countries - looking more holistically using the gender inequality index in addition to the employment levels of males vs females.*

```{r}
source("http://reuningscherer.net/multivariate/r/ciscoreplot.R.txt")

ciscoreplot(pc1, c(1, 2), data[, 1])

```
*There don't appear to be any clear trends/groupings in our score plot of the first and second principle component. There are 2 outliers in our 95% confidence ellipse of our 2 retained components - the countries Yemen and Madagascar. Madagascar appears to fall outside of the ellipse in the direction of the second component only slightly (this is in large part due to it's orientation in relation to the first principle component) and Yemen lies outside the ellipse in the direction of the second principle component by a good margin. Our interpretations of the 95% confidence ellipse are valid given we have a multivariate normal distribution in our dataset as shown in the chi-square quantile plot and is a necessary condition for interpreating the ellipse.*

```{r}
biplot(pc1, choices = c(1, 2), pc.biplot = TRUE, cex = 0.7)
```
*The biplot shows the distribution of countries based on their principle component scores in relation to the first and second principle component.The arrows show the strength of a variables contribution (the magnitude) while the direction underscores how the variable contributed. Similar to the plot above, there doesn't appear to be many trends between the principal component scores of the countries. However, the arrows re-inforce our interpretation of the principle components, as the second principal component is comprised mainly of the female/male labor force and gender development index (the arrows point up) while the first component is comprised of development variables such as GNI per capita or mortality rate, which point in opposite directions since they are negatively correlated. Likewise, when the arrows are perpendicular, it's reflected by a smaller loading in defining that principle component as we saw in the data.*

*Based on our findings, we were able to utilize PCA since our variables had strong correlations, a linear relationship and were normally distributed (although this point itself isn't necessary for PCA it allowed us to use methods like parallel anaylsis). We were able to capture approximately 78% of the total variance using two principle components which we derived using a varitey of methods including a scree plot, parallel analysis and eigenvalue criteria. The first principle component captures the overall development of a country with variables that captured high levels of developing having a relatively large and positive loading while variables that demonstrated lower development had large and negative loadings. In contrast, the second principle component focused solely on gender equality and included variables relating to female/male labor employment and the gender inequality index. Finally, we created a score plot (with 95% confidence interval ellipse) and a biplot to analyze our results; in the 95% confidence interval ellipse, there were 2 outliers which is unsurprising given we had over 150 observations and the deviation for one of those outliers was negligable in the direction of the second component. Lastly, the biplot validated our interpretations of the principle components and was valid given we verified the multinormality of our data's distribution.*

